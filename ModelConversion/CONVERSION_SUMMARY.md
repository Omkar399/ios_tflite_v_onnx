# Model Conversion Summary ‚úÖ

## Status: All Models Successfully Converted!

Date: November 5, 2025

## üì¶ Generated Models

All models are in the `models/` directory:

| Model | Format | Precision | Size | Status |
|-------|--------|-----------|------|--------|
| mobilenetv3_small_fp32.tflite | TFLite | FP32 | 9.7 MB | ‚úÖ Verified |
| mobilenetv3_small_fp16.tflite | TFLite | FP16 | 4.9 MB | ‚úÖ Verified |
| mobilenetv3_small_int8.tflite | TFLite | INT8 | 2.7 MB | ‚úÖ Verified |
| mobilenetv3_small_fp32.onnx | ONNX | FP32 | 9.7 MB | ‚úÖ Verified |
| mobilenetv3_small_fp16.onnx | ONNX | FP16 | 4.9 MB | ‚úÖ Verified |

**Total:** 5 models ready for iOS benchmarking

## üõ†Ô∏è Technical Details

### Conversion Environment

- **Python:** 3.11
- **TensorFlow:** 2.20.0
- **PyTorch:** 2.1.0 (downgraded from 2.9.0 due to ONNX export crashes)
- **NumPy:** 1.26.4 (downgraded from 2.3.4 for PyTorch compatibility)
- **ONNX:** 1.19.1
- **ONNX Runtime:** 1.23.2

### Key Challenges & Solutions

#### Challenge 1: Python 3.13 Incompatibility
- **Problem:** `onnxsim` failed to build with Python 3.13
- **Solution:** Used Python 3.11 instead

#### Challenge 2: Threading Conflicts
- **Problem:** Importing TensorFlow + PyTorch + ONNX libraries together caused mutex lock failures
- **Solution:** Created separate independent scripts with lazy imports

#### Challenge 3: PyTorch 2.9.0 ONNX Export Crashes
- **Problem:** PyTorch 2.9.0 ONNX export caused segmentation faults on macOS ARM
- **Root Cause:** New dynamo-based export + opset version conversion issues
- **Solution:** Downgraded to PyTorch 2.1.0 with NumPy 1.x

#### Challenge 4: NumPy 2.x Incompatibility
- **Problem:** PyTorch 2.1.0 compiled against NumPy 1.x, incompatible with NumPy 2.x
- **Solution:** Pinned NumPy <2.0 in requirements.txt

## üìã Conversion Scripts

Two clean, independent scripts were created:

### 1. `convert_to_tflite.py`
- Converts using TensorFlow/Keras
- Generates FP32, FP16, and INT8 variants
- Includes built-in verification
- **Status:** Works perfectly

### 2. `convert_to_onnx.py`
- Converts using PyTorch/torchvision
- Generates FP32 and FP16 variants
- Uses ONNX opset 17
- **Status:** Works with PyTorch 2.1.0

### Usage

```bash
# Activate environment
cd ModelConversion
source venv/bin/activate

# Convert to TFLite
python convert_to_tflite.py --model-size small --output-dir models

# Convert to ONNX
python convert_to_onnx.py --model-size small --output-dir models
```

## ‚úÖ Verification Results

### TFLite Models

All TFLite models verified successfully:
- **Input Shape:** `[1, 224, 224, 3]` (NHWC format)
- **Output Shape:** `[1, 1000]` (ImageNet classes)
- **Runtime:** TensorFlow Lite Interpreter

### ONNX Models

All ONNX models verified successfully:
- **FP32:**
  - Input: `[1, 3, 224, 224]` (NCHW format), dtype: float32
  - Output: `[1, 1000]`, dtype: float32
- **FP16:**
  - Input: `[1, 3, 224, 224]` (NCHW format), dtype: float16
  - Output: `[1, 1000]`, dtype: float16
- **Runtime:** ONNX Runtime with CPUExecutionProvider

## üì± Next Steps for iOS Integration

1. **Copy Models:**
   ```bash
   # Copy TFLite models
   cp models/*.tflite ../TFLiteCoreMLDemo/Models/
   
   # Copy ONNX models
   cp models/*.onnx ../ORTCoreMLDemo/Models/
   ```

2. **Xcode Integration:**
   - Open both iOS projects in Xcode
   - Verify model files appear in Project Navigator
   - Check "Target Membership" for each model file
   - Ensure models are included in app bundle

3. **Update Code:**
   - Update model filenames in app code if needed
   - TFLite uses NHWC format (H, W, C)
   - ONNX uses NCHW format (C, H, W)

## üìä Expected Results

### Model Sizes
- **FP32:** ~9.7 MB (baseline accuracy)
- **FP16:** ~4.9 MB (half size, minimal accuracy loss)
- **INT8:** ~2.7 MB (TFLite only, faster inference)

### Performance Expectations
- **INT8:** Fastest, smallest, slight accuracy trade-off
- **FP16:** Good balance of speed and accuracy
- **FP32:** Highest accuracy, slower inference

## üîß Environment Setup for Future Use

If you need to recreate the environment:

```bash
# Use Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install with locked versions
pip install --upgrade pip
pip install -r requirements.txt
```

## üìö Files Created

```
ModelConversion/
‚îú‚îÄ‚îÄ convert_to_tflite.py          # Independent TFLite conversion
‚îú‚îÄ‚îÄ convert_to_onnx.py             # Independent ONNX conversion
‚îú‚îÄ‚îÄ requirements.txt               # Pinned working versions
‚îú‚îÄ‚îÄ README.md                      # Detailed documentation
‚îú‚îÄ‚îÄ CONVERSION_SUMMARY.md          # This file
‚îî‚îÄ‚îÄ models/
    ‚îú‚îÄ‚îÄ mobilenetv3_small_fp32.tflite
    ‚îú‚îÄ‚îÄ mobilenetv3_small_fp16.tflite
    ‚îú‚îÄ‚îÄ mobilenetv3_small_int8.tflite
    ‚îú‚îÄ‚îÄ mobilenetv3_small_fp32.onnx
    ‚îî‚îÄ‚îÄ mobilenetv3_small_fp16.onnx
```

## üéâ Conclusion

All model conversions completed successfully! The system is ready for iOS benchmarking.

**Key Success Factors:**
- Used Python 3.11 for compatibility
- Downgraded PyTorch to 2.1.0 for stable ONNX export
- Pinned NumPy <2.0 for PyTorch compatibility
- Created independent scripts to avoid library conflicts
- Verified all models with inference tests

**Ready for:** iOS app integration and performance benchmarking

